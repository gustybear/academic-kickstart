@inproceedings{9053272,
 abstract = {Approximating kernel functions with random features (RFs) has been a successful application of random projections for nonparametric estimation. However, performing random projections presents computational challenges for large-scale problems. Recently, a new optical hardware called Optical Processing Unit (OPU) has been developed for fast and energy-efficient computation of large-scale RFs in the analog domain. More specifically, the OPU performs the multiplication of input vectors by a large random matrix with complexvalued i.i.d. Gaussian entries, followed by the application of an element-wise squared absolute value operation â€“ this last nonlinearity being intrinsic to the sensing process. In this paper, we show that this operation results in a dot-product kernel that has connections to the polynomial kernel, and we extend this computation to arbitrary powers of the feature map. Experiments demonstrate that the OPU kernel and its RF approximation achieve competitive performance in applications using kernel ridge regression and transfer learning for image classification. Crucially, thanks to the use of the OPU, these results are obtained with time and energy savings.},
 author = {R. Ohana and J. Wacker and J. Dong and S. Marmin and F. Krzakala and M. Filippone and L. Daudet},
 booktitle = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
 doi = {10.1109/ICASSP40776.2020.9053272},
 issn = {2379-190X},
 keywords = {Kernel methods;nonparametric estimation;optical computing;random features;kernel ridge regression},
 month = {May},
 number = {},
 pages = {9294-9298},
 title = {Kernel Computations from Large-Scale Random Features Obtained by Optical Processing Units},
 volume = {},
 year = {2020}
}

