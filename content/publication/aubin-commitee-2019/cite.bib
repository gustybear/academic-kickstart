@article{Aubin-commitee_2019,
 abstract = {Heuristic tools from statistical physics have been used in the past to locate the phase transitions and compute the optimal learning and generalization errors in the teacher-student scenario in multi-layer neural networks. In this paper, we provide a rigorous justification of these approaches for a two-layers neural network model called the committee machine, under a technical assumption. We also introduce a version of the approximate message passing (AMP) algorithm for the committee machine that allows optimal learning in polynomial time for a large set of parameters. We find that there are regimes in which a low generalization error is information-theoretically achievable while the AMP algorithm fails to deliver it; strongly suggesting that no efficient algorithm exists for those cases, unveiling a large computational gap.},
 author = {Benjamin Aubin and Antoine Maillard and Jean Barbier and Florent Krzakala and Nicolas Macris and Lenka Zdeborov√°},
 doi = {10.1088/1742-5468/ab43d2},
 journal = {Journal of Statistical Mechanics: Theory and Experiment},
 month = {dec},
 number = {12},
 pages = {124023},
 publisher = {IOP Publishing},
 title = {The committee machine: computational to statistical gaps in learning a two-layers neural network},
 url = {https://doi.org/10.1088%2F1742-5468%2Fab43d2},
 volume = {2019},
 year = {2019}
}

